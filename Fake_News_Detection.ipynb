{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Fake_News_Detection.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bVOeK1fzizt0",
        "colab_type": "text"
      },
      "source": [
        "## Import the libraries\n",
        "### Data manipulation libraries\n",
        "- **Pandas** is a python package or library to extract the data from the CSV into a DataFrame (table).\n",
        "- **Numpy** is a general-purpose array-processing package mostly used to process n-dimensional  matrices in python.\n",
        "\n",
        "### Machine Learning libraries\n",
        "#### `sklearn` is a python library that provides a range of machine learning algorithms. The following modules belong to it.\n",
        "  - `train_test_split` library is used to split the data into training and testing.\n",
        "  - `TfidfVectorizer` converts a collection of raw documents to a matrix containing TF-IDF features.\n",
        "  - `PassiveAggressiveClassifier` It is similar to the Perceptron in that it does not require a learning rate. However, contrary to the Perceptron, it includes a regularization parameter `C`.\n",
        "  - `accuracy_score` - In multilabel classification, this function computes subset accuracy: the set of labels predicted for a sample must exactly match the corresponding set of labels in `y_true`.\n",
        "  - `confusion_matrix` - Computes confusion matrix to evaluate the accuracy of a classification."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7GJsA052cF4l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Importing all the libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import PassiveAggressiveClassifier\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PwePjHfhkN_z",
        "colab_type": "text"
      },
      "source": [
        "## Load Fake News data\n",
        "We use pandas to import the data into a dataframe\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NOnRvufHcItA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Read the data\n",
        "df = pd.read_csv('fake_news_data.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qijswhyafgZH",
        "colab_type": "text"
      },
      "source": [
        "#### Get a snapshot of the data using `head()` function."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hgFjeTuofggd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Get shape and head\n",
        "print(df.shape)\n",
        "df.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sy4lm-UncSqy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# So the following line of code converts it into a unicode string format.\n",
        "# This operation is done to make sure the classifier doesn't run into mundane issues of encoding.\n",
        "df['text'] = df['text'].apply(lambda x: np.str_(x))\n",
        "\n",
        "# Get the labels\n",
        "labels=df.label\n",
        "labels.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k34BJNSdf2ku",
        "colab_type": "text"
      },
      "source": [
        "# Split data into training and test sets\n",
        "Split data into `training = 80%` and `testing = 20%` using `train_test_split` function:\n",
        "\n",
        "- `random_state` is used for initializing the internal random number generator, which will decide the splitting of data into train and test indices."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lACr0t_0fvs1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Split the dataset\n",
        "x_train,x_test,y_train,y_test=train_test_split(df['text'], labels, test_size=0.2, random_state=7)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lxvk1lunwYby",
        "colab_type": "text"
      },
      "source": [
        "## Machine learning code"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GKmSwOvFcXfm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Initialize a TfidfVectorizer\n",
        "tfidf_vectorizer=TfidfVectorizer(stop_words='english', max_df=0.7)\n",
        "# Fit and transform train set, transform test set\n",
        "tfidf_train=tfidf_vectorizer.fit_transform(x_train) \n",
        "tfidf_test=tfidf_vectorizer.transform(x_test)\n",
        "\n",
        "# Initialize a PassiveAggressiveClassifier\n",
        "pac=PassiveAggressiveClassifier(max_iter=50)\n",
        "pac.fit(tfidf_train,y_train)\n",
        "# Predict on the test set and calculate accuracy\n",
        "y_pred=pac.predict(tfidf_test)\n",
        "score=accuracy_score(y_test,y_pred)\n",
        "print(f'Accuracy: {round(score*100,2)}%')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7qTcTrd5ccRm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Build confusion matrix\n",
        "confusion_matrix(y_test,y_pred, labels=['FAKE','REAL'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2ZDUqeTmsTMF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(\"In this model, we have \"+\n",
        "      str(confusion_matrix(y_test,y_pred, labels=['FAKE','REAL']).tolist()[0][0])+ \" true positives (REAL news articles), \"+\n",
        "      str(confusion_matrix(y_test,y_pred, labels=['FAKE','REAL']).tolist()[1][1])+ \" true negatives (FAKE news articles),\\n \"+\n",
        "      str(confusion_matrix(y_test,y_pred, labels=['FAKE','REAL']).tolist()[1][0])+ \" false positives (REAL news articles predicted as FAKE), \"+\n",
        "      str(confusion_matrix(y_test,y_pred, labels=['FAKE','REAL']).tolist()[0][1])+ \" false negatives (FAKE news articles predicted as REAL), \")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b1KHUz-ukQh9",
        "colab_type": "text"
      },
      "source": [
        "# Prediction Block\n",
        "Prediction on wine quality can be performed by uploading the provided csv file `(option-1)` or typing real time features `(option-2)` like **title** and  **text** in real time to predict if the news article is FAKE or REAL.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a_M5zN4ikZA0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "option = int(input(\"Enter 1 or 2\\n 1. If you want to upload the prediction data file \\n 2. Write your own Prediction data\\n:\"))\n",
        "if(option==1):\n",
        "  # Loading prediction.csv file\n",
        "  df_1=pd.read_csv('fake_news_data_prediction.csv')\n",
        "  # Seperating features from csv file\n",
        "  x_pre= df_1.drop('label', axis=1)\n",
        "  # So the following line of code converts it into a unicode string format.\n",
        "  # This operation is done to make sure the classifier doesn't run into mundane issues of encoding.\n",
        "  df_1['text'] = df_1['text'].apply(lambda x: np.str_(x))\n",
        "  # Fit and transform Prediction set\n",
        "  fake_1=tfidf_vectorizer.transform(df_1['text'])\n",
        "  # Predicting news with given features\n",
        "  fake_pred_1=pac.predict(fake_1)\n",
        "  # Reshaping data into our needs\n",
        "  fake_pred_1=fake_pred_1.reshape(401,1)\n",
        "  # Adding the label column to the dataframe\n",
        "  df_1['label']=fake_pred_1\n",
        "  # Print dataframe\n",
        "  print('Here is the dataframe or table for prediction dataset with values:\\n',df_1)\n",
        "  df_1.to_csv('Prediction_Output.csv')\n",
        "\n",
        "else:\n",
        "  print(\"Here are the links to a few the websites:\\n\\nREAL News:\\n- http://www.bbc.com\\n- http://money.cnn.com\\n- http://edition.cnn.com\\n- http://abcnews.go.com\\n- http://www.bbc.co.uk\\\n",
        "  \\n\\nFAKE News:\\n- http://beforeitsnews.com\\n- https://www.activistpost.com\\n- http://dailybuzzlive.com\\n- http://www.disclose.tv\")\n",
        "  title=input(\"\\nCopy the headline of the news article here: \")\n",
        "  text=input(\"\\nCopy the body of the news article here: \\n\")\n",
        "  real_time_data = [text]  \n",
        "  # Create the pandas DataFrame \n",
        "  df_2 = pd.DataFrame(real_time_data, columns = ['text']) \n",
        "  df_2['text'] = df_2['text'].apply(lambda x: np.str_(x))\n",
        "  # Fit and transform Prediction set\n",
        "  fake_2=tfidf_vectorizer.transform(df_2['text'])\n",
        "  # Predicting news with given features\n",
        "  fake_pred_2=pac.predict(fake_2)\n",
        "  label=fake_pred_2[0]\n",
        "  # Here we are converting data into pandas dataframe which is nothing but a table format\n",
        "  real_time_data_2 = [[title,text,label]]  \n",
        "  # Create the pandas DataFrame \n",
        "  df_3 = pd.DataFrame(real_time_data_2, columns = ['title','text','label']) \n",
        "  # Print dataframe with prediction results. \n",
        "  print('\\n\\nHere is the dataframe or table for above entered values with prediction:\\n',df_3)\n",
        "  df_3.to_csv('Prediction_Output.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}
